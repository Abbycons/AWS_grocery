# ğŸ›’ AWS Grocery App - Terraform Deployment

  ğŸ“– Table of Contents 

ğŸš€Getting Started

   â— Introduction
   â— How It's Built (Infrastructure Overview)
   â— Architecture Diagrams

ğŸ—ï¸ Core Infrastructure

   â— Network & Security (VPC & Security Groups)
   â— Application Hosting (EC2, Auto Scaling & Load Balancer)
   â— Data & Storage (Database, S3 & ECR)
   â— Access Control (IAM Roles)
   â— Automation (Lambda & Step Functions)

âš™ï¸ Configuration & Deployment

   â— Terraform Modules
   â— Automated Deployment Workflow
   â— GitHub Secrets Setup
   â— Step-by-Step Deployment Guide

ğŸ”§ Operations & Support
   â— Troubleshooting Common Issues
   â— Frequently Asked Questions
   â— Technical Glossary

ğŸ“ˆ What's Next?
   â— Future Enhancements 
   â— Lambda Layer Creation Guide

ğŸ¤ Community
   â— Contributing Guidelines
   â— License Information

ğŸ Introduction
   This project was my capstone for the Cloud Track at Masterschool. The application
   itself was originally built by our fantastic Track Mentor, Alejandro RomÃ¡n â€” huge thanks 
   to him for the foundation!

   Our goal was to design and deploy the AWS infrastructure for the app, piece by piece.
   Rather than manually clicking through the AWS console, I decided to automate the entire
   process using Terraform and GitHub Actions.

   This approach makes the deployment repeatable, scalable, and much 
   less prone to human error.Everything from provisioning servers to 
   deploying the code is now handled automatically.

   For details on the application's features and how to run it locally, please see the 
   original README by Alejandro. This document focuses specifically on the cloud infrastructure
   and the automation pipeline that brings it all to life.

ğŸ—ï¸ Infrastructure Overview

   This Terraform project deploys a scalable grocery app on AWS. The core setup includes:
     â— Auto-scaling App Servers: EC2 instances in multiple zones, running in Docker.
     â— Managed Database: A secure, multi-AZ PostgreSQL RDS instance for high availability.
     â— Load Balancer: Distributes traffic evenly across the app servers.
     â— Cloud Storage: An S3 bucket for user avatars and backups.
   The architecture is built for security, scalability, and reliability.

ğŸ› ï¸ Terraform configuration
The Terraform configuration is modularized as follows:

/bootstrap
â”‚â”€â”€ main.tf
â”‚â”€â”€ variables.tf
/infrastructure
â”‚â”€â”€ /modules
â”‚   â”œâ”€â”€ alb
â”‚   â”œâ”€â”€ asg
â”‚   â”œâ”€â”€ ec2_launch_template
â”‚   â”œâ”€â”€ iam_ec2
â”‚   â”œâ”€â”€ iam_lambda
â”‚   â”œâ”€â”€ lambda
â”‚   â”œâ”€â”€ rds
â”‚   â”œâ”€â”€ s3_bucket
â”‚   â”œâ”€â”€ security_groups
â”‚   â”œâ”€â”€ vpc
â”‚â”€â”€ main.tf
â”‚â”€â”€ variables.tf
â”‚â”€â”€ outputs.tf
â”‚â”€â”€ terraform.tfvars
â”‚â”€â”€ lambda_data
â”‚â”€â”€ generate_backend.py

ğŸ¢ Infrastructure Components

ğŸ—ï¸ How It All Fits Together

ğŸŒ The Foundation (VPC & Security)
     â— A secure virtual network (VPC) with public areas for web servers and private
        areas for the database
     â— Carefully configured security rules that control exactly how each component 
       can communicate

ğŸ–¥ï¸ The Application Hosting
     â— Auto-scaling EC2 instances that automatically adjust to traffic demands  
     â— Each server runs our application from a Docker container stored in ECR
     â— A load balancer that smartly distributes traffic and checks server health

ğŸ—„ï¸ Data & Storage
     â— A reliable PostgreSQL database running in private, secure subnets
     â— S3 storage for user avatars, database backups, and application files

âš¡ The Automation Magic
     â— A clever system that automatically populates the database once everything is ready
     â— Uses Step Functions to coordinate the process and Lambda to execute the setup
     â— Each component has just the right permissions through IAM roles

ğŸ”„ How the Database Gets Populated Automatically

   This automated process ensures the database is ready to go as soon 
   as the infrastructure is up. Here's how it works:
   
  1. ğŸ¯ The Trigger
     When the SQL database file is uploaded to S3, an EventBridge rule notices it 
     and starts the Step Function.

   2. ğŸ§­ The Coordinator (Step Function)

     This is the brain of the operation - it checks everything is ready before proceeding:
     â— Waits for the database to be fully available and running
     â— Confirms the SQL file exists in S3 and is ready to use
     â— Only when both are ready does it trigger the Lambda function
     â— Handles any hiccups along the way with clear error messages

  3. âš¡ The Worker (Lambda Function)
  Once triggered, this function does the actual work:
     â— Fetches the SQL file from S3
     â— Connects to the database
     â— Runs the SQL commands to populate the database with all the necessary data

  4. ğŸ“ Monitoring & Safety Nets

     â— Complete visibility through CloudWatch logs for both the Step Function and Lambda
     â— Automatic error handling if anything goes wrong with the database, file, or function
     â— Retry logic that waits and checks again if things aren't ready yet

 ğŸ§© Building Blocks
    This setup uses dedicated Terraform modules to keep the code organized and reusable:

   Our infrastructure is built from reusable, focused modules that each handle 
    a specific part of the system. This makes the code easy to understand, update, 
    and maintain.
     â— vpc & security_groups: The secure network foundation, creating the 
       virtual private cloud and the firewall rules for all components.
     â— rds: The brain of the operationâ€”it sets up the managed PostgreSQL 
       database where all the application data lives.
     â— s3_bucket: Our cloud storage attic, securely holding user avatars,
       database dumps, and code for Lambda functions.
     â— iam_ec2 & iam_lambda: The identity managers, granting just the right 
       permissions to our EC2 instances and Lambda functions.
     â— ec2_launch_template & asg: The app hosting engine. This 
       defines the server blueprint and manages a self-healing, scalable group of 
       instances.

ğŸ¯ In Summary

   This Terraform project creates a solid, scalable foundation for the grocery app on AWS.
   By breaking the infrastructure into reusable modules, it's straightforward to maintain 
   and adapt for future needs. We've also automated key processesâ€”like populating the 
   database using Lambda and Step Functionsâ€”and leveraged S3 for versatile storage, making 
   the entire system both efficient and robust.

ğŸš€ How Deployment Works

   Our GitHub Actions workflow automatically builds and deploys everything when 
   code is pushed to the main branch. Here's the step-by-step process:

ğŸ” Secure Setup
     â— Checks out the code and securely connects to AWS using OIDC authentication
     â— Sets up Terraform with secure remote state storage

ğŸ—ï¸ Phase 1: Build the Foundation 
     â— Provisions core AWS infrastructure - the network, database, storage, 
       and security rules 
     â— Creates the container registry (ECR) where we'll store our application image

ğŸ³ Application Preparation
     â— Builds and tags the Docker image with the latest application code
     â— Pushes the image to our private container registry
     â— Sets up configuration by generating the necessary environment files

ğŸ’¾ Database Initialization
     â— Uploads the starter database file to S3, which automatically triggers our
       setup process
     â— The system waits for the database to be ready, then populates it with initial data
     â— This ensures the database is fully prepared before any application servers launch

âš¡ Phase 2: Launch the Application
     â— Deploys the remaining infrastructure - including the auto-scaling application servers
     â— Cleans up sensitive files and temporary resources
     â— Verifies everything is running and marks the deployment successful

ğŸ¯ Live Deployment Status

   Want to see if everything's running smoothly? Add this badge to your README 
   for real-time status:

   ![Deployment Status](https://github.com/<your-org>/<your-repo>/actions /workflows/
   deployment.yml/badge.svg)

   The badge automatically updates to show whether the latest deployment was successful. âœ…

ğŸš€ Quick Start Guide

  1. Set Up AWS
     â— Create an AWS account
     â— Create an IAM user with necessary permissions (EC2, RDS, S3, VPC, IAM, CloudWatch)
     â— Install and configure AWS CLI with your credentials
     â— Create an SSH key pair for EC2 access

  2. Get the Code 
     git clone https://github.com/AbbyconsAWS_grocery_v2.gitcd AWS_grocery_v2           
   
  3. Bootstrap Backend
     â— Navigate to bootstrap directory
     â— Create terraform.tfvars with your region, GitHub org/repo
     â— Run the setup script to create Terraform state storage  

  4. Configure GitHub Secrets
     Add these secrets in your GitHub repo settings:
     â— AWS role ARN and region
     â— Database credentials
     â— S3 bucket name (must be unique)
     â— SSH key name and allowed IP
     â— JWT secret key

  5. Deploy
     Push to main branch - the GitHub Actions workflow will automatically:
     â— Build and push Docker image to ECR
     â— Provision all AWS infrastructure
     â— Set up database with initial data
     â— Launch the application

  6. Access Your App 
     Check the GitHub Actions output for the load balancer URL, then visit it in your browser!

ğŸ›‘ Clean Up
  Run terraform destroy in both infrastructure and bootstrap directories to remove all resources.

  ğŸ”™Need to Rollback?
     â— Use terraform destroy to remove everything
     â— Or manually deploy previous Docker images
     â— Database backups are available in S3

  This automated pipeline ensures secure, repeatable deployments with minimal manual steps!

ğŸ› ï¸ Common Issues & Fixes

ğŸš« Terraform Plan Fails
     â— Usually means: Missing or incorrect GitHub Secrets
     â— Quick fix: Double-check all required variables are set in your repository secrets

ğŸ–¥ï¸ EC2 Instances Won't Start
     â— Common causes: Missing IAM permissions or issues with the startup script
     â— What to check: Verify the EC2 IAM role and check system logs for error messages

ğŸ—„ï¸Database Not Populating
     â— Likely culprit: Lambda can't access S3 or connect to RDS
     â— Troubleshoot: Confirm the Lambda role has proper S3 permissions and the RDS security
       group allows Lambda connections

ğŸ’¡Tip: Check the GitHub Actions logs - they usually point directly to what's wrong!

â“Frequently Asked Questions

  1. How do I change the instance type?
     Update the instance_type variable in your terraform.tfvars file.
  2. How can I connect to the database?
     Use the RDS endpoint (shown in Terraform outputs) from an EC2 instance.
  3. How do I add new components?
     Create or modify modules in the modules directory.

ğŸ“–Quick Glossary
     â— VPC: Virtual Private Cloud (your AWS network)
     â— ALB: Application Load Balancer (traffic distributor)
     â— ASG: Auto Scaling Group (self-adjusting servers)
     â— ECR: Elastic Container Registry (Docker image storage)
     â— RDS: Relational Database Service (managed database)
     â— IAM: Identity and Access Management (permissions)
     â— OIDC: OpenID Connect (secure authentication)

ğŸš€What's Next?

  Planned Improvements
       â— Enhanced CI/CD pipelines for smoother deployments

  Recently Completed âœ…
       â— AWS Lambda for database migrations
       â— Terraform Remote Backend for state management
       â— Lambda layer for Python dependencies

ğŸ› ï¸Building the Lambda Layer
  We package Python dependencies (boto3 & psycopg2) into a Lambda layer using Docker 
  for AWS compatibility.

  Project Structure
  lambda_layer_docker_project/
  â”œâ”€â”€ lambda_layer/          # Docker build files
  â”œâ”€â”€ output/               # Generated layer ZIP
  â””â”€â”€ lambda_function/      # Your Lambda code

  Quick Build Commands
# Build the layer container
  docker build -t lambda-layer .

# Generate the ZIP file
  docker run --rm -v $(pwd)/output:/output lambda-layer

  The resulting lambda-layer.zip in the output/ folder is ready for AWS.

  ğŸ¤ Contributing
  We love community contributions!

  1. Fork the repository
  2. Create your feature branch (git checkout -b feature/amazing-feature)
  3. Commit your changes (git commit -m 'Add amazing feature')
  4. Push and open a Pull Request

ğŸ“œ License
   MIT Licensed - free for non-commercial use.





